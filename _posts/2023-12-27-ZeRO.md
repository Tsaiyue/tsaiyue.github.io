---
title: ZeRO related blogging
date: 2023-12-27 14:10:00 +0800
categories: [VRAM Efficient Technique, ZeRO]
tags: [HPC]
render_with_liquid: false
---

### **ZeRO: Memory Optimizations Toward Training Trillion Parameter Models [1]**

#### TL; DR: 总结ZeRO相关显存优化方式，包括面向数据并行DP的ZeRO-DP以及减小显存冗余的Zero-R技术。

#### **1 ZeRO-DP**

##### **- 解决的问题：**

- 数据并行DP(Data Parallel)并行效率上效果明显,但其存在显存利用存在冗余的问题，即在每一个Device上都需要存储完整的**模型参数、权重梯度以及优化器状态**。因此ZeRO-DP的目的在于**为数据并行赋能**，在考虑通信成本前提下较少显存的冗余占用，以此实现更高效地训练规模更大的模型；ZeRO-DP提出三种递进式的优化策略，将上述显存中的冗余占用在不同Device上进行分片；
- 在混合精度的优化策略下，通常模型权重和梯度采用fp16精度，而优化器件的计算需要采用fp32精度，以ADAM为例优化器的状态(OS: Optimizer State)需要保存的数据由三部分组成，分别为**模型参数备份、momentent以及variance**，这使得优化器状态(OS)所占用的显存空间将大约站3/4。这部分的冗余占用较大，不利于扩大模型规模；
- 相较于模型并行MP，DP具有更好的扩张效率，其原因在于MP降低了计算的粒度导致其带来更大的通信负担，容易形成分布式训练瓶颈；

##### **- 技术重点：**

**- ZeRO stage1(OS):** 每个Device只保存一部分的优化器状态，各自得到一份梯度，并采用All_Reduce得到完整梯度信息，后基于对应的优化器状态和梯度对对应权重进行更新，最后将所有Device上的权重进行All_Gather；

**- ZeRO stage2(OS+G):** 每个Device只保存一部分的优化器状态和权重梯度信息，在进行前反向计算之后，每个Device各得到一份梯度，后对所有Device上的梯度进行Reduce_Scatter，根据每个Device上对应的优化器状态(OS)和梯度(G)对对应的权重(W)进行更新，后对所有Device上的权重进行All_Gather;

**- ZeRO stage1(OS+G+W):** 由于权重(W)分布在不同的Device上，故在进行前向计算之前，需通过All_Gather将不同Device的权重都汇聚到一个Device上，完成前向计算之后只保留对应位置的权重，将其他权重去除；计算Backward对权重的处理过程与Forward同；Backward之后得到的梯度进行Reduce_Scatter得到对应部分的梯度，最后维护对应部分的权重(W)。三个阶段带来的优化效果如下图：
  
  <center>
      <img style="border-radius: 0.3125em;
      box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
      src="https://github.com/Tsaiyue/tsaiyue.github.io/assets/46399096/a38b2872-2e40-4587-9ba9-8111f241acd2" width = "65%" alt=""/>
      <br>
      <div style="color:orange; border-bottom: 1px solid #d9d9d9;
      display: inline-block;
      color: #999;
      padding: 2px;">
        Fig1: ZeRO-DP三种递进式优化策略效果
        </div>
  </center>

#### **1 ZeRO-R**

##### **- 技术重点：**

**- 对部分激活值进行分片处理：** 若不考虑Gpipe中提及的重计算，则需要保存前向计算的激活值，若考虑重计算，则需要对前向过程进行重复计算；因此一种折中方式为仅仅保存深度网络前向过程的部分激活值，在进行反向计算的时候可以从最近的被保存的激活值开始计算，该想法来源于Training Deep Nets with Sublinear Memory Cost[2]；而ZeRO-R的其中一个技术重点就是对这部分保存的激活值进行分片；

**- 将部分计算和存储下放到CPU(ZeRO-offload)：** 为节省GPU显存，可考虑将部分计算和存储下放到CPU，但需要考虑的问题是，下放哪一部分计算和存储到GPU，但需要保证避免GPU和CPU的通信或CPU的计算成为瓶颈。如下图所示为每次训练迭代的计算流程图，主要有三部分组成，分别为前向计算、反向计算以及参数更新，除此之外还包括精度转换。可根据计算复杂度，将前向计算和反向计算放在GPU中，参数更新和精度转换操作则由CPU负责。
  
  <center>
      <img style="border-radius: 0.3125em;
      box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
      src="https://github.com/Tsaiyue/tsaiyue.github.io/assets/46399096/25cc99ab-e430-4e65-b01b-e341780daa55" width = "65%" alt=""/>
      <br>
      <div style="color:orange; border-bottom: 1px solid #d9d9d9;
      display: inline-block;
      color: #999;
      padding: 2px;">
        Fig2: 一次训练迭代的计算流程图
        </div>
  </center>

##### - 参考：

- [1] Microsoft ZeRO paper: https://arxiv.org/abs/1910.02054

- [2] [[1604.06174] Training Deep Nets with Sublinear Memory Cost](https://arxiv.org/abs/1604.06174)

- [3] https://github.com/microsoft/DeepSpeed
